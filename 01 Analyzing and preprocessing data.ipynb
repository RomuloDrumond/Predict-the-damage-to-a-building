{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This jupyter notebook contains a quick attempt to build a good predictive model for this competition:\n",
    "\n",
    "https://www.hackerearth.com/problem/machine-learning/predict-the-energy-used-612632a9-3f496e7f/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv(\"./dataset/train.csv\")\n",
    "test  = pd.read_csv(\"./dataset/test.csv\")\n",
    "build_own = pd.read_csv(\"./dataset/Building_Ownership_Use.csv\") \n",
    "build_str = pd.read_csv(\"./dataset/Building_Structure.csv\")\n",
    "\n",
    "# Merging dataframes where their columns are equal\n",
    "build_data = pd.merge(build_str, build_own, on=['building_id', 'district_id', 'vdcmun_id', 'ward_id'])\n",
    "\n",
    "# train dataset with features of build_own and build_str dataframes\n",
    "trainFull  = pd.merge(train, build_data, on=['building_id', 'district_id', 'vdcmun_id'])\n",
    "# test dataset with features of build_own and build_str dataframes\n",
    "testFull   = pd.merge(test,  build_data, on=['building_id', 'district_id', 'vdcmun_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainFull.shape: (631761, 53)\n",
      "testFull.shape:  (421175, 52)\n"
     ]
    }
   ],
   "source": [
    "print(\"trainFull.shape: \"+str(trainFull.shape)+\"\\n\"+\"testFull.shape:  \"+str(testFull.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Converting categorical features to numerical (and dealing with *NaN* entries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Dropping datapoint with *NaN*'s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number os *NaN*'s in each feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainFull:\n",
      "has_repair_started    33417\n",
      "count_families            1\n",
      "dtype: int64\n",
      "\n",
      "tesFull:\n",
      "has_repair_started    21922\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Features where the number of NaN's is nonzero\n",
    "print(\"trainFull:\")\n",
    "print(trainFull.isnull().sum().loc[trainFull.isnull().sum()!=0])#\n",
    "print(\"\\ntesFull:\")\n",
    "print(testFull.isnull().sum().loc[testFull.isnull().sum()!=0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see in the training dataset that the feature *has_repair_started* has 33417 *NaN*'s and *count_families* has only 1 *NaN*. In the test dataset only *has_repair_started* shows up again with 21922 *NaN*'s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we only have one instance of *NaN* in *count_families*, and more important, **it only happens in the training dataset**, we will drop this data point/row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples:\n",
      "trainCutted: 631760\n",
      "trainFull:   631761\n",
      "\n",
      "trainCutted NaN's:\n",
      "has_repair_started    33417\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Dropping data point with NaN in count_families features\n",
    "trainCutted = trainFull[np.isfinite(trainFull['count_families'])]\n",
    "\n",
    "# Showing results\n",
    "print(\"Number of samples:\\ntrainCutted: {}\\ntrainFull:   {}\\n\".format(len(trainCutted), len(trainFull)))\n",
    "print(\"trainCutted NaN's:\\n\"+str(trainCutted.isnull().sum().loc[trainCutted.isnull().sum()!=0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frequency analysis of *has_repair_started* feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    409222\n",
       "1.0    189121\n",
       "NaN     33417\n",
       "Name: has_repair_started, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(trainCutted.loc[:, 'has_repair_started'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the number of *NaN*'s is high (33417), we won't cut these data points. It's possible that *NaN*'s in *has_repair_started* feature be relevant information for the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Using dummy variables for categorical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting train dataset between *X_tr* and *Y_tr*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y_tr are the target classes\n",
    "Y_tr = trainCutted.loc[:, 'damage_grade'].copy()\n",
    "# Converting Y_tr to numerical format\n",
    "for i in range(len(Y_tr)):\n",
    "    Y_tr.values[i] = int(Y_tr.values[i][-1])\n",
    "\n",
    "Y_tr = Y_tr.astype('int') # change from object -> int\n",
    "    \n",
    "# X_tr are the features:\n",
    "features = trainCutted.columns.values.tolist()\n",
    "features.remove('damage_grade')\n",
    "X_tr = trainCutted.loc[:, features].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we search for differences between the train and test sets features values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             TRAIN == TEST:\n",
      "area_assesed\n",
      "district_id\n",
      "has_geotechnical_risk\n",
      "has_geotechnical_risk_fault_crack\n",
      "has_geotechnical_risk_flood\n",
      "has_geotechnical_risk_land_settlement\n",
      "has_geotechnical_risk_landslide\n",
      "has_geotechnical_risk_liquefaction\n",
      "has_geotechnical_risk_other\n",
      "has_geotechnical_risk_rock_fall\n",
      "count_floors_pre_eq\n",
      "count_floors_post_eq\n",
      "land_surface_condition\n",
      "foundation_type\n",
      "roof_type\n",
      "ground_floor_type\n",
      "other_floor_type\n",
      "position\n",
      "plan_configuration\n",
      "has_superstructure_adobe_mud\n",
      "has_superstructure_mud_mortar_stone\n",
      "has_superstructure_stone_flag\n",
      "has_superstructure_cement_mortar_stone\n",
      "has_superstructure_mud_mortar_brick\n",
      "has_superstructure_cement_mortar_brick\n",
      "has_superstructure_timber\n",
      "has_superstructure_bamboo\n",
      "has_superstructure_rc_non_engineered\n",
      "has_superstructure_rc_engineered\n",
      "has_superstructure_other\n",
      "condition_post_eq\n",
      "legal_ownership_status\n",
      "has_secondary_use\n",
      "has_secondary_use_agriculture\n",
      "has_secondary_use_hotel\n",
      "has_secondary_use_rental\n",
      "has_secondary_use_institution\n",
      "has_secondary_use_school\n",
      "has_secondary_use_industry\n",
      "has_secondary_use_health_post\n",
      "has_secondary_use_gov_office\n",
      "has_secondary_use_use_police\n",
      "has_secondary_use_other\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "                                             TRAIN != TEST:\n",
      "building_id\n",
      "train (631760)\n",
      "['100594f58f3' '100594f59bb' '100594f5a21' ... 'f7851a1478' 'f7851a14d6'\n",
      " 'f7851a153b']\n",
      "test (421175)\n",
      "['100594f5952' '100594f5a88' '100594f5ae4' ... 'f7851a12e5' 'f7851a13ae'\n",
      " 'f7851a15a3']\n",
      "\n",
      "has_repair_started\n",
      "train (3)\n",
      "[ 0.  1. nan]\n",
      "test (3)\n",
      "[ 0.  1. nan]\n",
      "\n",
      "vdcmun_id\n",
      "train (1420)\n",
      "[ 701  702  703 ... 5140 5141 5142]\n",
      "test (1419)\n",
      "[ 701  702  703 ... 5140 5141 5142]\n",
      "\n",
      "ward_id\n",
      "train (12301)\n",
      "[ 70102  70103  70105 ... 514207 514208 514209]\n",
      "test (12048)\n",
      "[ 70102  70103  70106 ... 514207 514208 514209]\n",
      "\n",
      "age_building\n",
      "train (178)\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 120 121 122 123 124 125 126\n",
      " 127 128 129 130 131 132 133 135 136 138 140 141 142 145 146 148 149 150\n",
      " 151 152 153 154 156 158 160 161 162 164 165 166 167 168 170 172 173 174\n",
      " 175 176 177 178 180 181 185 188 190 192 193 195 196 199 200 999]\n",
      "test (172)\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 140 141 142 143 144 145 146 149\n",
      " 150 151 152 154 155 156 157 159 160 162 163 165 166 168 170 173 174 175\n",
      " 176 178 180 187 190 192 195 198 200 999]\n",
      "\n",
      "plinth_area_sq_ft\n",
      "train (2069)\n",
      "[  70   71   72 ... 5000 5160 5220]\n",
      "test (1885)\n",
      "[  70   71   72 ... 4803 4928 5000]\n",
      "\n",
      "height_ft_pre_eq\n",
      "train (78)\n",
      "[ 6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29\n",
      " 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n",
      " 54 55 56 57 58 59 60 61 63 64 65 66 67 70 71 72 74 75 76 77 78 80 85 89\n",
      " 90 93 95 96 97 99]\n",
      "test (74)\n",
      "[  6   7   8   9  10  11  12  13  14  15  16  17  18  19  20  21  22  23\n",
      "  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41\n",
      "  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  60\n",
      "  63  64  65  67  68  70  72  74  75  76  77  78  80  81  90  95  96  99\n",
      " 273 305]\n",
      "\n",
      "height_ft_post_eq\n",
      "train (79)\n",
      "[  0   6   7   8   9  10  11  12  13  14  15  16  17  18  19  20  21  22\n",
      "  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40\n",
      "  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58\n",
      "  59  60  61  63  64  65  66  67  70  72  73  75  80  82  85  87  90  93\n",
      "  95  96  99 123 164 193 206]\n",
      "test (73)\n",
      "[  0   6   7   8   9  10  11  12  13  14  15  16  17  18  19  20  21  22\n",
      "  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40\n",
      "  41  42  43  44  45  46  47  48  49  50  51  52  54  55  56  57  58  60\n",
      "  63  64  65  67  68  70  71  72  75  76  77  78  80  81  95  97 113 153\n",
      " 180]\n",
      "\n",
      "count_families\n",
      "train (11)\n",
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 11.]\n",
      "test (10)\n",
      "[0. 1. 2. 3. 4. 5. 6. 7. 8. 9.]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Comparing test and train features values\n",
    "columns = testFull.columns.values\n",
    "equal     = \"\"\n",
    "different = \"\"\n",
    "for column in columns:\n",
    "    temp1 = trainCutted[column].unique()\n",
    "    temp1.sort()\n",
    "    temp2 = testFull[column].unique()\n",
    "    temp2.sort()\n",
    "\n",
    "    if np.array_equal(temp1, temp2):\n",
    "        equal+=column+\"\\n\"\n",
    "    else:\n",
    "        different+=column+\"\\n\"+\\\n",
    "        \"train ({})\\n{}\\n\".format(len(temp1), temp1)+\\\n",
    "        \"test ({})\\n{}\".format(len(temp2), temp2)+\"\\n\\n\"\n",
    "\n",
    "spaces = 45\n",
    "print(\"{}TRAIN == TEST:\\n{}\\n\".format(\" \"*spaces, equal))\n",
    "print(\"=\"*100+\"\\n\\n\")\n",
    "print(\"{}TRAIN != TEST:\\n{}\".format(\" \"*spaces, different))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating and adding dummies to the dataset: (**OBS: WE WILL DROP ONE OF THE *K* VARIABLES, REMAINING THEN K-1 DUMMY VARIABLES PER CATEGORICAL COLUMN**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(631760, 113)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr_new = X_tr\n",
    "\n",
    "# Categorical features that need encoding\n",
    "catFeat = [\n",
    "    'area_assesed',\n",
    "    'district_id',\n",
    "    'land_surface_condition',\n",
    "    'foundation_type',\n",
    "    'roof_type',\n",
    "    'ground_floor_type',\n",
    "    'other_floor_type',\n",
    "    'position',\n",
    "    'plan_configuration',\n",
    "    'condition_post_eq',\n",
    "    'legal_ownership_status',\n",
    "#   'has_repair_started', # because of NaN's\n",
    "]   \n",
    "\n",
    "# Numerical/Ordinal feautures\n",
    "numFeat = [\n",
    "    'building_id', # searching for data leakage\n",
    "    'vdcmun_id',   # categorical, but used as numerical for simplicity\n",
    "    'ward_id',     # categorical, but used as numerical for simplicity\n",
    "    'count_floors_pre_eq',\n",
    "    'count_floors_post_eq',\n",
    "    'age_building',\n",
    "    'plinth_area_sq_ft',\n",
    "    'height_ft_pre_eq',\n",
    "    'height_ft_post_eq',\n",
    "    'count_families'\n",
    "]\n",
    "\n",
    "X_tr_new = pd.get_dummies(X_tr,     columns=catFeat,                drop_first=True)\n",
    "X_tr_new = pd.get_dummies(X_tr_new, columns=['has_repair_started'], drop_first=True, dummy_na=True) # because of NaN's\n",
    "X_tr_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting 'building_id' to numerical format (searching for data leakage)\n",
    "X_num = X_tr_new\n",
    "\n",
    "X_num['building_id'] = X_num['building_id'].apply(lambda x: int(x,16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving dataframes to CSV files\n",
    "X_num.to_csv(\"X_tr.csv\", index=False)\n",
    "Y_tr.to_csv(\"Y_tr.csv\", header=False, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
