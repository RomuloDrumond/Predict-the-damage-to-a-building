{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Dimensionality reduction and reevaluation of models</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary:\n",
    "\n",
    "1. [Loading preprocessed dataset, functions and hyperparameters](#load_data)\n",
    "\n",
    "\n",
    "2. [Dimensionality reduction with models reevaluation](#dim_reduction)\n",
    "    \n",
    "    2.1. [k-NN](#k-NN)\n",
    "\n",
    "    2.2. [Linear regression](#linear_regression)\n",
    "    \n",
    "    2.3. [Logistic regression](#logistic_regression)\n",
    "    \n",
    "    2.4. [Nearest Centroid Classifier (NCC)](#ncc)\n",
    "    \n",
    "    2.5. [Quadratic Gaussian Classifier (QGC)](#qgc)\n",
    "    \n",
    "    2.6. [Decison trees](#decision_trees)\n",
    "    \n",
    "    2.7. [Artificial Neural Network (ANN)](#ann)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loading preprocessed data set, functions and hyperparameters <a class=\"anchor\" id=\"load_data\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_tr.shape: (631760, 113)\n",
      "Y_tr.shape: (631760, 1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "X_tr = pd.read_csv(\"X_tr.csv\")\n",
    "Y_tr = pd.read_csv(\"Y_tr.csv\", header=None)\n",
    "\n",
    "print(\"X_tr.shape: {}\\nY_tr.shape: {}\".format(X_tr.shape, Y_tr.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary function to tell when processing is over\n",
    "def is_over(): # linux os\n",
    "    import os\n",
    "    os.system('spd-say \"your program has finished\"')\n",
    "    \n",
    "# Function for scaling numerical features\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "def scale_feat(X_train, X_test, featIndex, scaleType='min-max'):\n",
    "    if scaleType=='min-max' or scaleType=='std':\n",
    "        X_tr_norm = np.copy(X_train) # making a copy to let the original available\n",
    "        X_ts_norm = np.copy(X_test)\n",
    "        scaler = MinMaxScaler(copy=False) if scaleType=='min-max' else StandardScaler(copy=False)\n",
    "        scaler.fit(X_tr_norm[:,featIndex])\n",
    "        X_tr_norm[:,featIndex] = scaler.transform(X_tr_norm[:,featIndex])\n",
    "        X_ts_norm[:,featIndex] = scaler.transform(X_ts_norm[:,featIndex])\n",
    "        return (X_tr_norm, X_ts_norm)\n",
    "    else:\n",
    "        raise ValueError(\"Type of scaling not defined. Use 'min-max' or 'std' instead.\")\n",
    "        \n",
    "import numpy as np\n",
    "\n",
    "# Hyperparameters:\n",
    "# Numerical/Ordinal feautures\n",
    "numFeat = [\n",
    "    'building_id', # searching for data leakage\n",
    "    'vdcmun_id',   # categorical, but used as numerical for simplicity\n",
    "    'ward_id',     # categorical, but used as numerical for simplicity\n",
    "    'count_floors_pre_eq',\n",
    "    'count_floors_post_eq',\n",
    "    'age_building',\n",
    "    'plinth_area_sq_ft',\n",
    "    'height_ft_pre_eq',\n",
    "    'height_ft_post_eq',\n",
    "    'count_families'\n",
    "]\n",
    "\n",
    "# Train/Test split = 80% train and 20% test\n",
    "test_size = 0.2\n",
    "\n",
    "# Index of columns to be scaled\n",
    "numFeat_idx = np.in1d(X_tr.columns.values, numFeat).nonzero()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of resamplings\n",
    "n_resamplings = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objective function\n",
    "def f_o(u):\n",
    "    return np.mean(u) - 2*np.std(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_values = X_tr.values # taking the numpy matrix of dataframe\n",
    "Y_values = np.ravel(Y_tr.values) # taking numpy column array from dataframe and converting to simple array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Dimensionality reduction with models reevaluation <a class=\"anchor\" id=\"dim_reduction\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this notebook is to use dimensionality reduction, in this case, *Principal Component Analysis* (PCA), to decrease the time needed to process the data when training the machine learning models.\n",
    "\n",
    "As a hyperparameter, the conserved variance, $p$, was set to 98%. Also, the type of feature scaling was set to `min-max` as many transformed categorical features now have values `0` or `1`, so, using standard scaling may result in the original numerical features dominating the PCA transformation, as they would have values ranging from `-1` to `+1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.98\n",
    "scaleType = 'min-max'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the code below we show the number of dimensions in the case that we apply dimensionality reduction in the whole data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum variance conserved: 98.0%\n",
      "# dimensions: 69\n",
      "CPU times: user 1min 25s, sys: 6.13 s, total: 1min 31s\n",
      "Wall time: 14.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "X_tr_norm, _ = scale_feat(X_tr.values, X_tr.values, featIndex=numFeat_idx, scaleType='min-max')\n",
    "\n",
    "pca = PCA(n_components=p)\n",
    "pca.fit(X_tr_norm)\n",
    "    \n",
    "print(\"Minimum variance conserved: {}%\".format(p*100))\n",
    "print(\"# dimensions: {}\".format(len(pca.components_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the PCA is applied after the features scaling, which depends on the train/test split, this notebook will contain a lot of copy and paste from the previous one (*02 Building and evaluation of ML models*).\n",
    "\n",
    "Giving that the time to process the data was usually reduced a longer hyperparameters search as conducted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 k-NN <a class=\"anchor\" id=\"k-NN\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05c93c4ef91941708e988b112343ff60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='ks', max=6, style=ProgressStyle(description_width='initial'))…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caea37e65fea4099bd608bfac1e8bba3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='n_resamplings', max=10, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c8601198a2243c081a302804bab5795",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='n_resamplings', max=10, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0d1c98eefca4382ac14432ebc401f22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='n_resamplings', max=10, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ae3215176ec4c57af6822c7aac0818b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='n_resamplings', max=10, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "692a234ab2b94d3db3277701da7f39ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='n_resamplings', max=10, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70c40c476e924aa5a9fbc8f3553937ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='n_resamplings', max=10, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20h 46min 29s, sys: 6min 1s, total: 20h 52min 31s\n",
      "Wall time: 2h 50min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "\n",
    "header = [\"k\", \"$\\mu$\", \"$\\sigma$\", \"$f_o$\"]\n",
    "ks = np.linspace(1,10, num=6, dtype='int').tolist() # possible values of k\n",
    "\n",
    "nn_data = np.zeros((len(ks), len(header)))\n",
    "for i in tqdm_notebook(range(len(ks)), desc='ks'):\n",
    "    results = [0]*n_resamplings\n",
    "    for j in tqdm_notebook(range(n_resamplings), desc='n_resamplings'):\n",
    "        # Train/validation split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_values, Y_values, test_size=test_size)\n",
    "\n",
    "        # scaling\n",
    "        X_tr_norm, X_ts_norm = scale_feat(X_train, X_test, featIndex=numFeat_idx, scaleType=scaleType)\n",
    "        \n",
    "        # PCA\n",
    "        pca = PCA(n_components = p)\n",
    "        pca.fit(X_tr_norm)\n",
    "        \n",
    "        pca_X_tr_norm = pca.transform(X_tr_norm)\n",
    "        pca_X_ts_norm = pca.transform(X_ts_norm)\n",
    "        \n",
    "        # model fitting\n",
    "        k_nn = KNeighborsClassifier(n_neighbors=ks[i], n_jobs=-1)\n",
    "        k_nn.fit(pca_X_tr_norm, y_train)\n",
    "\n",
    "        # model evaluation\n",
    "        y_pred = k_nn.predict(pca_X_ts_norm)\n",
    "        results[j] = f1_score(y_test, y_pred, average='weighted')\n",
    "        \n",
    "    \n",
    "    nn_data[i,:] = np.matrix([ks[i], np.mean(results), np.std(results), f_o(results)])\n",
    "\n",
    "df_pca_knn = pd.DataFrame(nn_data, columns=header)\n",
    "\n",
    "is_over()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving results\n",
    "# filename = \"./simulation_results/df_pca_knn.csv\"\n",
    "# df_pca_knn.to_csv(filename, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_pca_knn:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>$\\mu$</th>\n",
       "      <th>$\\sigma$</th>\n",
       "      <th>$f_o$</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.705696</td>\n",
       "      <td>0.000974</td>\n",
       "      <td>0.703747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.697567</td>\n",
       "      <td>0.000832</td>\n",
       "      <td>0.695903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.720170</td>\n",
       "      <td>0.001066</td>\n",
       "      <td>0.718038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.724551</td>\n",
       "      <td>0.001226</td>\n",
       "      <td>0.722099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.729181</td>\n",
       "      <td>0.001154</td>\n",
       "      <td>0.726872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.730667</td>\n",
       "      <td>0.000710</td>\n",
       "      <td>0.729246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      k     $\\mu$  $\\sigma$     $f_o$\n",
       "0   1.0  0.705696  0.000974  0.703747\n",
       "1   2.0  0.697567  0.000832  0.695903\n",
       "2   4.0  0.720170  0.001066  0.718038\n",
       "3   6.0  0.724551  0.001226  0.722099\n",
       "4   8.0  0.729181  0.001154  0.726872\n",
       "5  10.0  0.730667  0.000710  0.729246"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_knn:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>$\\mu$</th>\n",
       "      <th>$\\sigma$</th>\n",
       "      <th>$f_o$</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.700718</td>\n",
       "      <td>0.001065</td>\n",
       "      <td>0.698588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.724440</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>0.722045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.731552</td>\n",
       "      <td>0.001212</td>\n",
       "      <td>0.729127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      k     $\\mu$  $\\sigma$     $f_o$\n",
       "0   1.0  0.700718  0.001065  0.698588\n",
       "1   5.0  0.724440  0.001197  0.722045\n",
       "2  10.0  0.731552  0.001212  0.729127"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# loading results\n",
    "df_pca_knn = pd.read_csv(\"./simulation_results/df_pca_knn.csv\", sep='\\t')\n",
    "print('df_pca_knn:')\n",
    "display(df_pca_knn)\n",
    "\n",
    "df_knn = pd.read_csv(\"./simulation_results/df_knn.csv\", sep='\\t')\n",
    "print('df_knn:')\n",
    "display(df_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the k-NN classifier applied in the transformed data set was slightly better, but the notorious difference is the processing time:\n",
    "\n",
    "* Original k-NN took 13h 29min 2s while searching for 3 different cases of hyperparameters;\n",
    "\n",
    "* The combination of PCA + k-NN took 2h 50min 31s while searching for double the number of hyperparameters cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Linear regression <a class=\"anchor\" id=\"linear_regression\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the multilabel version of Y_tr\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "Y_tr_multilabel = mlb.fit_transform(Y_tr.values) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4480703b70f6416f9965afeb1bf962a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='n_resamplings', max=10, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 14min 36s, sys: 1min 21s, total: 15min 57s\n",
      "Wall time: 2min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "\n",
    "header = [\"$\\mu$\", \"$\\sigma$\", \"$f_o$\"]\n",
    "\n",
    "results = [0]*n_resamplings\n",
    "for i in tnrange(n_resamplings, desc='n_resamplings'):\n",
    "    # Train/validation split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_values, Y_tr_multilabel, test_size=test_size)\n",
    "\n",
    "    # scaling\n",
    "    X_tr_norm, X_ts_norm = scale_feat(X_train, X_test, featIndex=numFeat_idx, scaleType=scaleType)\n",
    "\n",
    "    # PCA\n",
    "    pca = PCA(n_components = p)\n",
    "    pca.fit(X_tr_norm)\n",
    "\n",
    "    pca_X_tr_norm = pca.transform(X_tr_norm)\n",
    "    pca_X_ts_norm = pca.transform(X_ts_norm)\n",
    "\n",
    "    # model fitting\n",
    "    reg = linear_model.LinearRegression(n_jobs=-1)\n",
    "    reg.fit(pca_X_tr_norm, y_train)\n",
    "\n",
    "    # model evaluation\n",
    "    y_pred = np.argmax(reg.predict(pca_X_ts_norm), axis=1).astype(str) # +1???\n",
    "    y_pred = mlb.fit_transform(y_pred)\n",
    "\n",
    "    results[i] = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "\n",
    "reg_data = np.matrix([np.mean(results), np.std(results), f_o(results)])\n",
    "\n",
    "df_pca_reg = pd.DataFrame(reg_data, columns=header)\n",
    "# display(df_reg)\n",
    "is_over()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving results\n",
    "# filename = \"./simulation_results/df_pca_reg.csv\"\n",
    "# df_pca_reg.to_csv(filename, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_pca_reg:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>$\\mu$</th>\n",
       "      <th>$\\sigma$</th>\n",
       "      <th>$f_o$</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.70277</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>0.701202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     $\\mu$  $\\sigma$     $f_o$\n",
       "0  0.70277  0.000784  0.701202"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_reg:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scaleType</th>\n",
       "      <th>$\\mu$</th>\n",
       "      <th>$\\sigma$</th>\n",
       "      <th>$f_o$</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>min-max</td>\n",
       "      <td>0.707567</td>\n",
       "      <td>0.001361</td>\n",
       "      <td>0.704845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>std</td>\n",
       "      <td>0.707680</td>\n",
       "      <td>0.001097</td>\n",
       "      <td>0.705486</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  scaleType     $\\mu$  $\\sigma$     $f_o$\n",
       "0   min-max  0.707567  0.001361  0.704845\n",
       "1       std  0.707680  0.001097  0.705486"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# loading results\n",
    "df_pca_reg = pd.read_csv(\"./simulation_results/df_pca_reg.csv\", sep='\\t')\n",
    "print('df_pca_reg:')\n",
    "display(df_pca_reg)\n",
    "\n",
    "df_reg = pd.read_csv(\"./simulation_results/df_reg.csv\", sep='\\t')\n",
    "print('df_reg:')\n",
    "display(df_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the linear regression case, we had a drop in performance and no reduction in processing time. This is probably because finding the PCA transform takes a significant time when compared to the model fitting time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Logistic regression <a class=\"anchor\" id=\"logistic_regression\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "rhos = [0, 0.5, 1] # rho=0 <=> l2 norm / rho==1 <=> l1 norm\n",
    "Cs = [10**x for x in range(-1,+1 +1)]\n",
    "\n",
    "header = [\"$rho$\", \"$C$\", \"$\\mu$\", \"$\\sigma$\", \"$f_o$\"]\n",
    "logreg_data = np.empty((len(rhos)*len(Cs), len(header)), dtype=object)\n",
    "count=0\n",
    "for rho in tqdm_notebook(rhos, desc=\"rho's: \"):\n",
    "    for C in tqdm_notebook(Cs, desc=\"C's\"):\n",
    "#         print(\"Started penalty={}/C={} at {}\".format(penalty, C, datetime.datetime.now()))\n",
    "        results = [0]*n_resamplings\n",
    "        for i in tnrange(n_resamplings, desc='resampling :', leave=False):\n",
    "            # Train/validation split\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X_values, Y_values, test_size=test_size)\n",
    "\n",
    "            # scaling\n",
    "            X_tr_norm, X_ts_norm = scale_feat(X_train, X_test, featIndex=numFeat_idx, scaleType=scaleType)\n",
    "\n",
    "            # PCA\n",
    "            pca = PCA(n_components = p)\n",
    "            pca.fit(X_tr_norm)\n",
    "\n",
    "            pca_X_tr_norm = pca.transform(X_tr_norm)\n",
    "            pca_X_ts_norm = pca.transform(X_ts_norm)\n",
    "            \n",
    "            # model fitting\n",
    "            logreg = linear_model.LogisticRegression(multi_class='multinomial',solver='saga',\n",
    "                                                     penalty='elasticnet',max_iter=500, tol=1e-4, \n",
    "                                                     l1_ratio=rho, C=C,  n_jobs=-1)\n",
    "            logreg.fit(pca_X_tr_norm, y_train)\n",
    "\n",
    "            # model evaluation\n",
    "            y_pred = logreg.predict(pca_X_ts_norm)\n",
    "            results[i] = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "        logreg_data[count,:] = np.matrix([rho, C, np.mean(results), np.std(results), f_o(results)])\n",
    "        count+=1\n",
    "\n",
    "df_pca_logreg = pd.DataFrame(logreg_data, columns=header)\n",
    "is_over()\n",
    "\n",
    "'''\n",
    "Original model:\n",
    "CPU times: user 15h 57min 10s, sys: 1min 22s, total: 15h 58min 33s\n",
    "Wall time: 15h 57min\n",
    "\n",
    "New model:\n",
    "CPU times: user 10h 49min 55s, sys: 8min 29s, total: 10h 58min 25s\n",
    "Wall time: 9h 22min 6s\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving results\n",
    "# filename = \"./simulation_results/df_pca_logreg.csv\"\n",
    "# df_pca_logreg.to_csv(filename, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_pca_logreg:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>$rho$</th>\n",
       "      <th>$C$</th>\n",
       "      <th>$\\mu$</th>\n",
       "      <th>$\\sigma$</th>\n",
       "      <th>$f_o$</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.711120</td>\n",
       "      <td>0.000617</td>\n",
       "      <td>0.709885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.710984</td>\n",
       "      <td>0.000968</td>\n",
       "      <td>0.709047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.711000</td>\n",
       "      <td>0.001155</td>\n",
       "      <td>0.708689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.710448</td>\n",
       "      <td>0.000896</td>\n",
       "      <td>0.708656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.710393</td>\n",
       "      <td>0.000910</td>\n",
       "      <td>0.708572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.709856</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.708478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.710814</td>\n",
       "      <td>0.001219</td>\n",
       "      <td>0.708376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.708937</td>\n",
       "      <td>0.000981</td>\n",
       "      <td>0.706976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.708259</td>\n",
       "      <td>0.001078</td>\n",
       "      <td>0.706104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   $rho$   $C$     $\\mu$  $\\sigma$     $f_o$\n",
       "7    1.0   1.0  0.711120  0.000617  0.709885\n",
       "4    0.5   1.0  0.710984  0.000968  0.709047\n",
       "5    0.5  10.0  0.711000  0.001155  0.708689\n",
       "1    0.0   1.0  0.710448  0.000896  0.708656\n",
       "2    0.0  10.0  0.710393  0.000910  0.708572\n",
       "6    1.0   0.1  0.709856  0.000689  0.708478\n",
       "8    1.0  10.0  0.710814  0.001219  0.708376\n",
       "3    0.5   0.1  0.708937  0.000981  0.706976\n",
       "0    0.0   0.1  0.708259  0.001078  0.706104"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_logreg:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>$rho$</th>\n",
       "      <th>$C$</th>\n",
       "      <th>$\\mu$</th>\n",
       "      <th>$\\sigma$</th>\n",
       "      <th>$f_o$</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.718680</td>\n",
       "      <td>0.000901</td>\n",
       "      <td>0.716878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.718251</td>\n",
       "      <td>0.000835</td>\n",
       "      <td>0.716582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.718541</td>\n",
       "      <td>0.001046</td>\n",
       "      <td>0.716449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.718173</td>\n",
       "      <td>0.000922</td>\n",
       "      <td>0.716328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.718408</td>\n",
       "      <td>0.001210</td>\n",
       "      <td>0.715988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.718665</td>\n",
       "      <td>0.001632</td>\n",
       "      <td>0.715401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.717804</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.715204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.717645</td>\n",
       "      <td>0.001321</td>\n",
       "      <td>0.715004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.716944</td>\n",
       "      <td>0.001352</td>\n",
       "      <td>0.714240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   $rho$   $C$     $\\mu$  $\\sigma$     $f_o$\n",
       "6    1.0   0.1  0.718680  0.000901  0.716878\n",
       "4    0.5   1.0  0.718251  0.000835  0.716582\n",
       "2    0.0  10.0  0.718541  0.001046  0.716449\n",
       "7    1.0   1.0  0.718173  0.000922  0.716328\n",
       "1    0.0   1.0  0.718408  0.001210  0.715988\n",
       "5    0.5  10.0  0.718665  0.001632  0.715401\n",
       "8    1.0  10.0  0.717804  0.001300  0.715204\n",
       "3    0.5   0.1  0.717645  0.001321  0.715004\n",
       "0    0.0   0.1  0.716944  0.001352  0.714240"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# loading results\n",
    "df_pca_logreg = pd.read_csv(\"./simulation_results/df_pca_logreg.csv\", sep='\\t')\n",
    "print('df_pca_logreg:')\n",
    "display(df_pca_logreg.sort_values(by=['$f_o$'], ascending=False))\n",
    "\n",
    "df_logreg = pd.read_csv(\"./simulation_results/df_logreg.csv\", sep='\\t')\n",
    "print('df_logreg:')\n",
    "display(df_logreg.sort_values(by=['$f_o$'], ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We had a slight drop in performance (from $f_o = 0.716878$ to $0.709885$) and in processing time (from 15h 57min to 9h 22min 6s)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Nearest Centroid Classifier (NCC) <a class=\"anchor\" id=\"ncc\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>$\\mu$</th>\n",
       "      <th>$\\sigma$</th>\n",
       "      <th>$f_o$</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.646854</td>\n",
       "      <td>0.000999</td>\n",
       "      <td>0.644857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      $\\mu$  $\\sigma$     $f_o$\n",
       "0  0.646854  0.000999  0.644857"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12min 15s, sys: 1min 8s, total: 13min 23s\n",
      "Wall time: 2min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from classifiers import NearestCentroid\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "header = [\"$\\mu$\", \"$\\sigma$\", \"$f_o$\"]\n",
    "\n",
    "# ncc_data = np.empty(len(header)), dtype=object)\n",
    "results = [0]*n_resamplings\n",
    "for i in range(n_resamplings):\n",
    "    # Train/validation split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_values, Y_tr.values, test_size=test_size)\n",
    "\n",
    "    # scaling\n",
    "    X_tr_norm, X_ts_norm = scale_feat(X_train, X_test, featIndex=numFeat_idx, scaleType=scaleType)\n",
    "    \n",
    "    # PCA\n",
    "    pca = PCA(n_components = p)\n",
    "    pca.fit(X_tr_norm)\n",
    "\n",
    "    pca_X_tr_norm = pca.transform(X_tr_norm)\n",
    "    pca_X_ts_norm = pca.transform(X_ts_norm)\n",
    "\n",
    "    # model fitting\n",
    "    ncc = NearestCentroid()\n",
    "    ncc.fit(pca_X_tr_norm, y_train)\n",
    "\n",
    "    # model evaluation\n",
    "    y_pred = ncc.predict(pca_X_ts_norm)\n",
    "    results[i] = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "ncc_data = np.matrix([np.mean(results), np.std(results), f_o(results)])\n",
    "\n",
    "df_ncc = pd.DataFrame(ncc_data, columns=header)\n",
    "display(df_ncc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we had similar performance and an increase in processing time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5. Quadratic Gaussian Classifier (QGC) <a class=\"anchor\" id=\"qgc\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9baa890160f47578f54ffb8aa66bcbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='variants: ', max=3, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='resampling :', max=10, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='resampling :', max=10, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='resampling :', max=10, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 1h 27min 57s, sys: 6min 52s, total: 1h 34min 49s\n",
      "Wall time: 56min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from classifiers import QuadraticGaussianClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "\n",
    "n_resamplings=10\n",
    "\n",
    "variants = [1, 2, 3]\n",
    "lambdas = np.linspace(0,1,num=12)[1:-1] # we crop 0 and 1 because:\n",
    "                                        # lambda=0 => original QGC\n",
    "                                        # lambda=1 => variant 2 of QGC\n",
    "header = [\"variant\",\"$\\lambda$\", \"$\\mu$\", \"$\\sigma$\", \"$f_o$\"]\n",
    "qgc_data = np.empty((2 + len(lambdas), len(header)), dtype=object)\n",
    "\n",
    "for variant in tqdm_notebook(variants, desc=\"variants: \"):\n",
    "    results = [0]*n_resamplings if variant!=3 else np.zeros((len(lambdas),n_resamplings))\n",
    "    for i in tnrange(n_resamplings, desc='resampling :', leave=False):\n",
    "        # Train/validation split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_tr.values, Y_tr.values, test_size=test_size)\n",
    "        \n",
    "        # scaling\n",
    "        X_tr_norm, X_ts_norm = scale_feat(X_train, X_test, featIndex=numFeat_idx, scaleType=scaleType)\n",
    "        \n",
    "        # PCA\n",
    "        pca = PCA(n_components = p)\n",
    "        pca.fit(X_tr_norm)\n",
    "\n",
    "        pca_X_tr_norm = pca.transform(X_tr_norm)\n",
    "        pca_X_ts_norm = pca.transform(X_ts_norm)\n",
    "        \n",
    "        if variant!=3:\n",
    "            # model fitting\n",
    "            qgc = QuadraticGaussianClassifier(variant=variant)\n",
    "            qgc.fit(pca_X_tr_norm, y_train)\n",
    "            \n",
    "            # model evaluation\n",
    "            y_pred = qgc.predict(pca_X_ts_norm)\n",
    "            results[i] = f1_score(y_test, y_pred, average='weighted')\n",
    "            \n",
    "        else:\n",
    "            for j in range(len(lambdas)): # for each lambda\n",
    "                # model fitting\n",
    "                qgc = QuadraticGaussianClassifier(variant=variant, Lambda=lambdas[j])\n",
    "                qgc.fit(pca_X_tr_norm, y_train)\n",
    "                \n",
    "                # model evaluation\n",
    "                y_pred = qgc.predict(pca_X_ts_norm)\n",
    "                results[j,i] = f1_score(y_test, y_pred, average='weighted')\n",
    "        \n",
    "    if variant!=3:\n",
    "        qgc_data[variant-1,:] = np.asmatrix(\n",
    "            [variant, np.nan, np.mean(results), np.std(results), f_o(results)]\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        var3_matrix = np.asmatrix([3]*len(lambdas)).T\n",
    "        lambdas_matrix  = np.asmatrix(lambdas).T\n",
    "        fo = [f_o(result) for result in results]\n",
    "        fo = np.asmatrix(fo).T\n",
    "        qgc_data[2:2+len(lambdas),:] = np.concatenate(\n",
    "            (var3_matrix, lambdas_matrix, np.asmatrix(np.mean(results,axis=1)).T, \n",
    "             np.asmatrix(np.std(results,axis=1)).T, fo), axis=1\n",
    "        )\n",
    "\n",
    "\n",
    "df_pca_qgc = pd.DataFrame(qgc_data, columns=header)\n",
    "is_over()\n",
    "\n",
    "'''\n",
    "Old time:\n",
    "CPU times: user 6h 20min 15s, sys: 4h 36min 1s, total: 10h 56min 17s\n",
    "Wall time: 2h 7min 30s\n",
    "\n",
    "New time:\n",
    "CPU times: user 1h 27min 57s, sys: 6min 52s, total: 1h 34min 49s\n",
    "Wall time: 56min 17s\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving results\n",
    "# filename = \"./simulation_results/df_pca_qgc.csv\"\n",
    "# df_pca_qgc.to_csv(filename, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_pca_qgc:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variant</th>\n",
       "      <th>$\\lambda$</th>\n",
       "      <th>$\\mu$</th>\n",
       "      <th>$\\sigma$</th>\n",
       "      <th>$f_o$</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.679278</td>\n",
       "      <td>0.001332</td>\n",
       "      <td>0.676614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.679278</td>\n",
       "      <td>0.001332</td>\n",
       "      <td>0.676614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.679278</td>\n",
       "      <td>0.001332</td>\n",
       "      <td>0.676614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.679278</td>\n",
       "      <td>0.001332</td>\n",
       "      <td>0.676614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.679278</td>\n",
       "      <td>0.001332</td>\n",
       "      <td>0.676614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.679278</td>\n",
       "      <td>0.001332</td>\n",
       "      <td>0.676614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.679278</td>\n",
       "      <td>0.001332</td>\n",
       "      <td>0.676614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.679278</td>\n",
       "      <td>0.001332</td>\n",
       "      <td>0.676614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.679278</td>\n",
       "      <td>0.001332</td>\n",
       "      <td>0.676614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.679278</td>\n",
       "      <td>0.001332</td>\n",
       "      <td>0.676614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.679127</td>\n",
       "      <td>0.001262</td>\n",
       "      <td>0.676602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.676702</td>\n",
       "      <td>0.001238</td>\n",
       "      <td>0.674227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    variant  $\\lambda$     $\\mu$  $\\sigma$     $f_o$\n",
       "2       3.0   0.090909  0.679278  0.001332  0.676614\n",
       "3       3.0   0.181818  0.679278  0.001332  0.676614\n",
       "4       3.0   0.272727  0.679278  0.001332  0.676614\n",
       "5       3.0   0.363636  0.679278  0.001332  0.676614\n",
       "6       3.0   0.454545  0.679278  0.001332  0.676614\n",
       "7       3.0   0.545455  0.679278  0.001332  0.676614\n",
       "8       3.0   0.636364  0.679278  0.001332  0.676614\n",
       "9       3.0   0.727273  0.679278  0.001332  0.676614\n",
       "10      3.0   0.818182  0.679278  0.001332  0.676614\n",
       "11      3.0   0.909091  0.679278  0.001332  0.676614\n",
       "1       2.0        NaN  0.679127  0.001262  0.676602\n",
       "0       1.0        NaN  0.676702  0.001238  0.674227"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_qgc:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variant</th>\n",
       "      <th>$\\lambda$</th>\n",
       "      <th>$\\mu$</th>\n",
       "      <th>$\\sigma$</th>\n",
       "      <th>$f_o$</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.635737</td>\n",
       "      <td>0.000768</td>\n",
       "      <td>0.634201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.632960</td>\n",
       "      <td>0.000848</td>\n",
       "      <td>0.631264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.632850</td>\n",
       "      <td>0.000848</td>\n",
       "      <td>0.631153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.632890</td>\n",
       "      <td>0.000871</td>\n",
       "      <td>0.631148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.632503</td>\n",
       "      <td>0.000860</td>\n",
       "      <td>0.630784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.631791</td>\n",
       "      <td>0.000820</td>\n",
       "      <td>0.630152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.629895</td>\n",
       "      <td>0.000721</td>\n",
       "      <td>0.628453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.627478</td>\n",
       "      <td>0.000775</td>\n",
       "      <td>0.625929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.616343</td>\n",
       "      <td>0.000785</td>\n",
       "      <td>0.614774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.603493</td>\n",
       "      <td>0.000727</td>\n",
       "      <td>0.602039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.565344</td>\n",
       "      <td>0.001093</td>\n",
       "      <td>0.563159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.509072</td>\n",
       "      <td>0.001531</td>\n",
       "      <td>0.506011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    variant  $\\lambda$     $\\mu$  $\\sigma$     $f_o$\n",
       "0       1.0        NaN  0.635737  0.000768  0.634201\n",
       "2       3.0   0.090909  0.632960  0.000848  0.631264\n",
       "4       3.0   0.272727  0.632850  0.000848  0.631153\n",
       "3       3.0   0.181818  0.632890  0.000871  0.631148\n",
       "5       3.0   0.363636  0.632503  0.000860  0.630784\n",
       "6       3.0   0.454545  0.631791  0.000820  0.630152\n",
       "7       3.0   0.545455  0.629895  0.000721  0.628453\n",
       "8       3.0   0.636364  0.627478  0.000775  0.625929\n",
       "9       3.0   0.727273  0.616343  0.000785  0.614774\n",
       "10      3.0   0.818182  0.603493  0.000727  0.602039\n",
       "11      3.0   0.909091  0.565344  0.001093  0.563159\n",
       "1       2.0        NaN  0.509072  0.001531  0.506011"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# loading results\n",
    "df_pca_qgc = pd.read_csv(\"./simulation_results/df_pca_qgc.csv\", sep='\\t')\n",
    "print('df_pca_qgc:')\n",
    "display(df_pca_qgc.sort_values(by=['$f_o$'], ascending=False))\n",
    "\n",
    "df_qgc = pd.read_csv(\"./simulation_results/df_qgc.csv\", sep='\\t')\n",
    "print(\"df_qgc:\")\n",
    "display(df_qgc.sort_values(by=['$f_o$'], ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we had a big improvement in performance and the processing time was reduced by half."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6. Decison trees <a class=\"anchor\" id=\"decision_trees\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b6276ce9ced420d8e4a57f3bc9ddc5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='case: ', max=16, style=ProgressStyle(description_width='initi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='resampling :', max=10, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='resampling :', max=10, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='resampling :', max=10, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='resampling :', max=10, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='resampling :', max=10, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='resampling :', max=10, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='resampling :', max=10, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='resampling :', max=10, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='resampling :', max=10, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='resampling :', max=10, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='resampling :', max=10, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='resampling :', max=10, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='resampling :', max=10, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='resampling :', max=10, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='resampling :', max=10, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='resampling :', max=10, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 8h 11min 24s, sys: 1h 47min 33s, total: 9h 58min 57s\n",
      "Wall time: 7h 40min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "\n",
    "cases = [\n",
    "    {\n",
    "    \"learning_rate\"     : learning_rate\n",
    "    ,'n_estimators'     : n_estimators\n",
    "    ,'max_depth'        : max_depth\n",
    "    ,'tree_method'      : 'gpu_hist'\n",
    "    ,'objective'        : 'multi:softmax'\n",
    "    } \n",
    "    # hyperparameters possible values\n",
    "    for learning_rate    in [1e-1, 0.3, 0.5, 1]\n",
    "    for n_estimators     in [500, 1000]\n",
    "    for max_depth        in [6, 12]\n",
    "]\n",
    "\n",
    "header = list(cases[0].keys())[:-2] + [\"$\\mu$\", \"$\\sigma$\", \"$f_o$\"] # no need for repeating\n",
    "                                                                     # 'tree_method' and 'objective'\n",
    "\n",
    "xgb_data = np.empty((len(cases), len(header)), dtype=object)\n",
    "count=0\n",
    "for case in tqdm_notebook(cases, desc=\"case: \"):\n",
    "#     print(\"Starting instance {}/{} at {}\".format(count+1, len(cases), datetime.datetime.now()))\n",
    "    results = [0]*n_resamplings \n",
    "    for i in tnrange(n_resamplings, desc='resampling :', leave=False):\n",
    "        # Train/test split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_values, Y_values, \n",
    "                                                            test_size=test_size)\n",
    "        # Train/validation split\n",
    "        X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, \n",
    "                                                                        test_size=test_size)\n",
    "\n",
    "        # scaling\n",
    "        X_tr_norm, X_ts_norm = scale_feat(X_train, X_test, featIndex=numFeat_idx, scaleType=scaleType)\n",
    "        X_val_norm, _ = scale_feat(X_validation, X_validation, featIndex=numFeat_idx, scaleType=scaleType)\n",
    "        \n",
    "        # PCA\n",
    "        pca = PCA(n_components = p)\n",
    "        pca.fit(X_tr_norm)\n",
    "\n",
    "        pca_X_tr_norm  = pca.transform(X_tr_norm)\n",
    "        pca_X_ts_norm  = pca.transform(X_ts_norm)\n",
    "        pca_X_val_norm = pca.transform(X_val_norm)\n",
    "        \n",
    "        # model fitting\n",
    "        xgb = XGBClassifier(**case)\n",
    "        xgb.fit(pca_X_tr_norm, y_train, eval_set=[(pca_X_val_norm,y_validation)]\n",
    "                ,early_stopping_rounds=30, verbose=False)\n",
    "                \n",
    "        # model evaluation\n",
    "        y_pred = xgb.predict(pca_X_ts_norm)\n",
    "        results[i] = f1_score(y_test, y_pred, average='weighted')\n",
    "            \n",
    "\n",
    "    xgb_data[count,:] = np.matrix(\n",
    "        list(case.values())[:-2] + [np.mean(results), np.std(results), f_o(results)])\n",
    "    count+=1\n",
    "        \n",
    "    \n",
    "df_pca_xgb = pd.DataFrame(xgb_data, columns=header)\n",
    "is_over()\n",
    "'''\n",
    "Old time:\n",
    "CPU times: user 11h 21min 42s, sys: 3h 37min 24s, total: 14h 59min 7s\n",
    "Wall time: 14h 59min\n",
    "\n",
    "New time:\n",
    "CPU times: user 8h 11min 24s, sys: 1h 47min 33s, total: 9h 58min 57s\n",
    "Wall time: 7h 40min 25s\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving results\n",
    "# df_pca_xgb.to_csv(\"./simulation_results/df_pca_xgb.csv\", sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_pca_xgb:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>$\\mu$</th>\n",
       "      <th>$\\sigma$</th>\n",
       "      <th>$f_o$</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.736385</td>\n",
       "      <td>0.001277</td>\n",
       "      <td>0.733830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>500.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.735723</td>\n",
       "      <td>0.001048</td>\n",
       "      <td>0.733627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.3</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.733833</td>\n",
       "      <td>0.000981</td>\n",
       "      <td>0.731870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.3</td>\n",
       "      <td>500.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.733779</td>\n",
       "      <td>0.001152</td>\n",
       "      <td>0.731476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.3</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.734421</td>\n",
       "      <td>0.001515</td>\n",
       "      <td>0.731392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   learning_rate  n_estimators  max_depth     $\\mu$  $\\sigma$     $f_o$\n",
       "3            0.1        1000.0       12.0  0.736385  0.001277  0.733830\n",
       "1            0.1         500.0       12.0  0.735723  0.001048  0.733627\n",
       "6            0.3        1000.0        6.0  0.733833  0.000981  0.731870\n",
       "5            0.3         500.0       12.0  0.733779  0.001152  0.731476\n",
       "7            0.3        1000.0       12.0  0.734421  0.001515  0.731392"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_xgb:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>$\\mu$</th>\n",
       "      <th>$\\sigma$</th>\n",
       "      <th>$f_o$</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>500.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.767047</td>\n",
       "      <td>0.001090</td>\n",
       "      <td>0.764868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.3</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.766257</td>\n",
       "      <td>0.001113</td>\n",
       "      <td>0.764031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.3</td>\n",
       "      <td>500.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.765584</td>\n",
       "      <td>0.000913</td>\n",
       "      <td>0.763758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.766463</td>\n",
       "      <td>0.001637</td>\n",
       "      <td>0.763188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.3</td>\n",
       "      <td>500.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.764780</td>\n",
       "      <td>0.001135</td>\n",
       "      <td>0.762511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   learning_rate  n_estimators  max_depth     $\\mu$  $\\sigma$     $f_o$\n",
       "1            0.1         500.0       12.0  0.767047  0.001090  0.764868\n",
       "7            0.3        1000.0       12.0  0.766257  0.001113  0.764031\n",
       "5            0.3         500.0       12.0  0.765584  0.000913  0.763758\n",
       "3            0.1        1000.0       12.0  0.766463  0.001637  0.763188\n",
       "4            0.3         500.0        6.0  0.764780  0.001135  0.762511"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# loading results\n",
    "df_pca_xgb = pd.read_csv(\"./simulation_results/df_pca_xgb.csv\", sep='\\t')\n",
    "df_xgb     = pd.read_csv(\"./simulation_results/df_xgb.csv\", sep='\\t')\n",
    "\n",
    "print('df_pca_xgb:')\n",
    "display(df_pca_xgb.sort_values(by=['$f_o$'], ascending=False).head())\n",
    "print('df_xgb:')\n",
    "display(df_xgb.sort_values(by=['$f_o$'], ascending=False).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We had a drop in performance but the processing time was cut by half."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7. Artificial Neural Network (ANN) <a class=\"anchor\" id=\"ann\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88517c9862c94d258a0e874f46f5da93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='case: ', max=14, style=ProgressStyle(description_width='initi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/romulo/ml_challenge6/venv/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='resampling :', max=10, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/romulo/ml_challenge6/venv/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='resampling :', max=10, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='resampling :', max=10, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='resampling :', max=10, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='resampling :', max=10, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='resampling :', max=10, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='resampling :', max=10, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='resampling :', max=10, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='resampling :', max=10, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='resampling :', max=10, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='resampling :', max=10, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='resampling :', max=10, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='resampling :', max=10, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='resampling :', max=10, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 1d 16h 19min 38s, sys: 4h 46min 33s, total: 1d 21h 6min 11s\n",
      "Wall time: 22h 9min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import f1_score\n",
    "from metric import f1\n",
    "\n",
    "\n",
    "Y_tr_categorical = to_categorical(Y_tr)[:, 1:] # change to categorical\n",
    "\n",
    "cases = [\n",
    "    {\n",
    "        'lr'  : lr,\n",
    "        'arq' : arq\n",
    "    } \n",
    "    # hyperparameters possible values\n",
    "    for arq in [\n",
    "                 [32],[128],[512]         # MLP with one   layer\n",
    "                ,[512,128], [128,32]      # //   //  two   layers\n",
    "                ,[512,128,32], [128,32,8] # //   //  three  //\n",
    "                ]\n",
    "    for lr in [1e-3, 1e-2]\n",
    "]\n",
    "\n",
    "header = list(cases[0].keys()) + [\"$\\mu$\", \"$\\sigma$\", \"$f_o$\"] \n",
    "\n",
    "ann_data = np.empty((len(cases), len(header)), dtype=object)\n",
    "count=0\n",
    "for case in tqdm_notebook(cases, desc=\"case: \"):\n",
    "    # model building\n",
    "    arq = case['arq']\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=arq[0], activation='relu', input_dim=69)) # first layer\n",
    "    for layer in arq:\n",
    "        model.add(Dense(units=layer, activation='relu'))\n",
    "    model.add(Dense(units=5, activation='softmax')) # output layer\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy'\n",
    "                 ,metrics=[f1]\n",
    "                 ,optimizer=Adam(lr=case['lr'], amsgrad=True)\n",
    "                 )\n",
    "    \n",
    "    results = [0]*n_resamplings\n",
    "    for i in tnrange(n_resamplings, desc='resampling :', leave=False):\n",
    "        # Train/validation split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_tr.values, Y_tr_categorical, test_size=test_size)\n",
    "\n",
    "        # scaling\n",
    "        X_tr_norm, X_ts_norm = scale_feat(X_train, X_test, featIndex=numFeat_idx, scaleType=\"min-max\")\n",
    "        \n",
    "        # PCA\n",
    "        pca = PCA(n_components = 69)\n",
    "        pca.fit(X_tr_norm)\n",
    "\n",
    "        pca_X_tr_norm  = pca.transform(X_tr_norm)\n",
    "        pca_X_ts_norm  = pca.transform(X_ts_norm)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # model fitting\n",
    "        es = EarlyStopping(monitor='val_f1', mode='max', verbose=0, patience=5)\n",
    "        history = model.fit(pca_X_tr_norm, y_train, shuffle=True \n",
    "                            ,epochs=1_000\n",
    "                            ,verbose=0\n",
    "                            ,validation_split=0.2\n",
    "                            ,callbacks=[es]\n",
    "                            )\n",
    "    \n",
    "        # model evaluation\n",
    "        y_pred = np.argmax(model.predict(pca_X_ts_norm), axis=1)+1\n",
    "        y_pred = to_categorical(y_pred)[:, 1:]\n",
    "        results[i] = f1_score(y_test, y_pred, average='weighted')\n",
    "                \n",
    "    ann_data[count,:] = np.matrix(list(case.values()) + [np.mean(results), np.std(results), f_o(results)])\n",
    "    count+=1\n",
    "        \n",
    "df_pca_ann = pd.DataFrame(ann_data, columns=header)\n",
    "is_over()\n",
    "\n",
    "'''\n",
    "Old model:\n",
    "CPU times: user 1d 7h 58min 2s, sys: 3h 33min 4s, total: 1d 11h 31min 6s\n",
    "Wall time: 18h 41min 29s\n",
    "\n",
    "New model:\n",
    "CPU times: user 1d 16h 19min 38s, sys: 4h 46min 33s, total: 1d 21h 6min 11s\n",
    "Wall time: 22h 9min 6s\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving results\n",
    "# df_pca_ann.to_csv(\"./simulation_results/df_pca_ann.csv\", sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_pca_ann:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr</th>\n",
       "      <th>arq</th>\n",
       "      <th>$\\mu$</th>\n",
       "      <th>$\\sigma$</th>\n",
       "      <th>$f_o$</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001</td>\n",
       "      <td>[128]</td>\n",
       "      <td>0.738402</td>\n",
       "      <td>0.003538</td>\n",
       "      <td>0.731327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.001</td>\n",
       "      <td>[128, 32]</td>\n",
       "      <td>0.737496</td>\n",
       "      <td>0.003756</td>\n",
       "      <td>0.729984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.001</td>\n",
       "      <td>[128, 32, 8]</td>\n",
       "      <td>0.736715</td>\n",
       "      <td>0.004054</td>\n",
       "      <td>0.728607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001</td>\n",
       "      <td>[512, 128]</td>\n",
       "      <td>0.755639</td>\n",
       "      <td>0.015378</td>\n",
       "      <td>0.724884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.010</td>\n",
       "      <td>[512, 128, 32]</td>\n",
       "      <td>0.734996</td>\n",
       "      <td>0.005391</td>\n",
       "      <td>0.724213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.001</td>\n",
       "      <td>[512, 128, 32]</td>\n",
       "      <td>0.754969</td>\n",
       "      <td>0.015465</td>\n",
       "      <td>0.724039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>[32]</td>\n",
       "      <td>0.727099</td>\n",
       "      <td>0.001573</td>\n",
       "      <td>0.723952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001</td>\n",
       "      <td>[512]</td>\n",
       "      <td>0.754622</td>\n",
       "      <td>0.015840</td>\n",
       "      <td>0.722942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.010</td>\n",
       "      <td>[128, 32, 8]</td>\n",
       "      <td>0.727965</td>\n",
       "      <td>0.003047</td>\n",
       "      <td>0.721872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.010</td>\n",
       "      <td>[512, 128]</td>\n",
       "      <td>0.734450</td>\n",
       "      <td>0.006460</td>\n",
       "      <td>0.721530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.010</td>\n",
       "      <td>[512]</td>\n",
       "      <td>0.731376</td>\n",
       "      <td>0.005887</td>\n",
       "      <td>0.719602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.010</td>\n",
       "      <td>[128, 32]</td>\n",
       "      <td>0.728224</td>\n",
       "      <td>0.004446</td>\n",
       "      <td>0.719332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.010</td>\n",
       "      <td>[128]</td>\n",
       "      <td>0.727418</td>\n",
       "      <td>0.004611</td>\n",
       "      <td>0.718195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010</td>\n",
       "      <td>[32]</td>\n",
       "      <td>0.720412</td>\n",
       "      <td>0.006708</td>\n",
       "      <td>0.706996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       lr             arq     $\\mu$  $\\sigma$     $f_o$\n",
       "2   0.001           [128]  0.738402  0.003538  0.731327\n",
       "8   0.001       [128, 32]  0.737496  0.003756  0.729984\n",
       "12  0.001    [128, 32, 8]  0.736715  0.004054  0.728607\n",
       "6   0.001      [512, 128]  0.755639  0.015378  0.724884\n",
       "11  0.010  [512, 128, 32]  0.734996  0.005391  0.724213\n",
       "10  0.001  [512, 128, 32]  0.754969  0.015465  0.724039\n",
       "0   0.001            [32]  0.727099  0.001573  0.723952\n",
       "4   0.001           [512]  0.754622  0.015840  0.722942\n",
       "13  0.010    [128, 32, 8]  0.727965  0.003047  0.721872\n",
       "7   0.010      [512, 128]  0.734450  0.006460  0.721530\n",
       "5   0.010           [512]  0.731376  0.005887  0.719602\n",
       "9   0.010       [128, 32]  0.728224  0.004446  0.719332\n",
       "3   0.010           [128]  0.727418  0.004611  0.718195\n",
       "1   0.010            [32]  0.720412  0.006708  0.706996"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_ann:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr</th>\n",
       "      <th>arq</th>\n",
       "      <th>$\\mu$</th>\n",
       "      <th>$\\sigma$</th>\n",
       "      <th>$f_o$</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.001</td>\n",
       "      <td>[128, 32]</td>\n",
       "      <td>0.748759</td>\n",
       "      <td>0.006041</td>\n",
       "      <td>0.736676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.001</td>\n",
       "      <td>[128, 32, 8]</td>\n",
       "      <td>0.749997</td>\n",
       "      <td>0.006790</td>\n",
       "      <td>0.736417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001</td>\n",
       "      <td>[128]</td>\n",
       "      <td>0.749068</td>\n",
       "      <td>0.006379</td>\n",
       "      <td>0.736310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.001</td>\n",
       "      <td>[512, 128, 32]</td>\n",
       "      <td>0.777009</td>\n",
       "      <td>0.020620</td>\n",
       "      <td>0.735770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.010</td>\n",
       "      <td>[512, 128, 32]</td>\n",
       "      <td>0.746012</td>\n",
       "      <td>0.005657</td>\n",
       "      <td>0.734699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001</td>\n",
       "      <td>[512, 128]</td>\n",
       "      <td>0.773487</td>\n",
       "      <td>0.019732</td>\n",
       "      <td>0.734022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001</td>\n",
       "      <td>[512]</td>\n",
       "      <td>0.770884</td>\n",
       "      <td>0.018516</td>\n",
       "      <td>0.733851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>[32]</td>\n",
       "      <td>0.736151</td>\n",
       "      <td>0.002087</td>\n",
       "      <td>0.731977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.010</td>\n",
       "      <td>[128, 32]</td>\n",
       "      <td>0.734137</td>\n",
       "      <td>0.003825</td>\n",
       "      <td>0.726487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.010</td>\n",
       "      <td>[128]</td>\n",
       "      <td>0.732377</td>\n",
       "      <td>0.004225</td>\n",
       "      <td>0.723928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.010</td>\n",
       "      <td>[512]</td>\n",
       "      <td>0.733888</td>\n",
       "      <td>0.005524</td>\n",
       "      <td>0.722840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.010</td>\n",
       "      <td>[512, 128]</td>\n",
       "      <td>0.735110</td>\n",
       "      <td>0.006714</td>\n",
       "      <td>0.721681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.010</td>\n",
       "      <td>[128, 32, 8]</td>\n",
       "      <td>0.733771</td>\n",
       "      <td>0.006741</td>\n",
       "      <td>0.720289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010</td>\n",
       "      <td>[32]</td>\n",
       "      <td>0.725900</td>\n",
       "      <td>0.006369</td>\n",
       "      <td>0.713162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       lr             arq     $\\mu$  $\\sigma$     $f_o$\n",
       "8   0.001       [128, 32]  0.748759  0.006041  0.736676\n",
       "12  0.001    [128, 32, 8]  0.749997  0.006790  0.736417\n",
       "2   0.001           [128]  0.749068  0.006379  0.736310\n",
       "10  0.001  [512, 128, 32]  0.777009  0.020620  0.735770\n",
       "11  0.010  [512, 128, 32]  0.746012  0.005657  0.734699\n",
       "6   0.001      [512, 128]  0.773487  0.019732  0.734022\n",
       "4   0.001           [512]  0.770884  0.018516  0.733851\n",
       "0   0.001            [32]  0.736151  0.002087  0.731977\n",
       "9   0.010       [128, 32]  0.734137  0.003825  0.726487\n",
       "3   0.010           [128]  0.732377  0.004225  0.723928\n",
       "5   0.010           [512]  0.733888  0.005524  0.722840\n",
       "7   0.010      [512, 128]  0.735110  0.006714  0.721681\n",
       "13  0.010    [128, 32, 8]  0.733771  0.006741  0.720289\n",
       "1   0.010            [32]  0.725900  0.006369  0.713162"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# loading results\n",
    "df_pca_ann = pd.read_csv(\"./simulation_results/df_pca_ann.csv\", sep='\\t')\n",
    "df_ann     = pd.read_csv(\"./simulation_results/df_ann.csv\", sep='\\t')\n",
    "\n",
    "print('df_pca_ann:')\n",
    "display(df_pca_ann.sort_values(by=['$f_o$'], ascending=False))\n",
    "print('df_ann:')\n",
    "display(df_ann.sort_values(by=['$f_o$'], ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see a drop in performance and an increase in processing time. The increase in processing time can be explained by the time necessary to find the PCA projection and the permanence of the old hyperparameters (the number of neurons in the hidden layers) which makes our new model have a similar size to the old one."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
